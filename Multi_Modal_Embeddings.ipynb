{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7YwxlK8CcIrrBgygOA1Oq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gohilriddhi21/embeddings/blob/main/Multi_Modal_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "ZrTFgQPWf7kO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load Data\n",
        "# Load product data\n",
        "df = pd.read_csv('products.csv')  # CSV with columns: product_id, description, image_path, ratings\n",
        "print(\"Product Data:\")\n",
        "print(df.head())\n",
        "\n",
        "# Load user history data\n",
        "user_history_df = pd.read_csv('user_history.csv')  # CSV with columns: user_id, product_id, rating, comment, likes\n",
        "print(\"\\nUser History Data:\")\n",
        "print(user_history_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPJLKWxKf88i",
        "outputId": "69baec63-f681-4d3e-8eef-c131592a584e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product Data:\n",
            "   product_id                 description          image_path  ratings\n",
            "0           1    Comfortable leather sofa   images/sofa1.jpeg      4.5\n",
            "1           2  Modern wooden dining table  images/table1.jpeg      4.0\n",
            "2           3      Soft cotton bed sheets  images/sheets1.jpg      4.7\n",
            "\n",
            "User History Data:\n",
            "   user_id  product_id  rating                 comment  likes\n",
            "0        1           1     4.5   Very comfortable sofa      1\n",
            "1        1           2     3.0  Table is sturdy but...      0\n",
            "2        2           3     5.0  Love these bed sheets!      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Generate Text Embeddings\n",
        "# Load a pre-trained text embedding model\n",
        "text_model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "rZS4wlKcgAcq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text embeddings for product descriptions\n",
        "text_embeddings = text_model.encode(df['description'].tolist())\n",
        "print(\"\\nText Embeddings Shape:\", text_embeddings.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmGCHSTmg-ft",
        "outputId": "cb9e628e-9db6-41bb-bc6e-4c584861baa6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text Embeddings Shape: (3, 384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Generate Image Embeddings\n",
        "# Load a pre-trained ResNet50 model for image embeddings\n",
        "image_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "\n",
        "def get_image_embedding(img_path):\n",
        "    \"\"\"Generate image embedding for a given image path.\"\"\"\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_data = image.img_to_array(img)\n",
        "    img_data = np.expand_dims(img_data, axis=0)\n",
        "    img_data = preprocess_input(img_data)\n",
        "    return image_model.predict(img_data).flatten()\n",
        "\n",
        "# Generate image embeddings for all product images\n",
        "image_embeddings = np.array([get_image_embedding(img_path) for img_path in df['image_path']])\n",
        "print(\"Image Embeddings Shape:\", image_embeddings.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJkqOEg4heDq",
        "outputId": "e09af13c-5901-402f-e63a-48068294cbd0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b9044659b20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "Image Embeddings Shape: (3, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 4: Combine Text and Image Embeddings\n",
        "# Concatenate text and image embeddings\n",
        "combined_embeddings = np.hstack((text_embeddings, image_embeddings))\n",
        "print(\"\\nCombined Embeddings Shape:\", combined_embeddings.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLdTL9OFhfWT",
        "outputId": "3631ca8c-6fd9-49f8-82ee-caf0ccaaf5f8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Combined Embeddings Shape: (3, 2432)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sR3uFxqBfAD7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 5: Create User Profile (Updated)\n",
        "def create_user_profile(user_id, user_history_df):\n",
        "    \"\"\"Create a user profile based on their history.\"\"\"\n",
        "    user_data = user_history_df[user_history_df['user_id'] == user_id]\n",
        "\n",
        "    # Average rating given by the user\n",
        "    avg_rating = user_data['rating'].mean()\n",
        "\n",
        "    # Combine all comments into a single text\n",
        "    combined_comments = \" \".join(user_data['comment'].dropna().tolist())\n",
        "\n",
        "    # Generate text embedding for the combined comments (using the same text model)\n",
        "    comment_embedding = text_model.encode(combined_comments)\n",
        "\n",
        "    # Get product IDs of liked products\n",
        "    liked_product_ids = user_data[user_data['likes'] == 1]['product_id'].tolist()\n",
        "\n",
        "    return {\n",
        "        'user_id': user_id,\n",
        "        'avg_rating': avg_rating,\n",
        "        'comment_embedding': comment_embedding,  # 384-dimensional\n",
        "        'liked_product_ids': liked_product_ids\n",
        "    }\n",
        "\n",
        "# Step 6: Recommend Products for a Specific User (Updated)\n",
        "def recommend_products(user_id, user_history_df, df, combined_embeddings, text_embeddings):\n",
        "    \"\"\"Recommend products for a given user_id.\"\"\"\n",
        "    # Create user profile\n",
        "    user_profile = create_user_profile(user_id, user_history_df)\n",
        "\n",
        "    # Get text embeddings for liked products\n",
        "    liked_product_indices = [df[df['product_id'] == pid].index[0] for pid in user_profile['liked_product_ids']]\n",
        "    liked_product_text_embeddings = text_embeddings[liked_product_indices]\n",
        "\n",
        "    # Calculate the average text embedding of liked products\n",
        "    liked_products_avg_text_embedding = np.mean(liked_product_text_embeddings, axis=0)\n",
        "\n",
        "    # Combine user's comment embedding with liked products' average text embedding\n",
        "    user_preference_embedding = 0.5 * user_profile['comment_embedding'] + 0.5 * liked_products_avg_text_embedding\n",
        "\n",
        "    # Normalize the user preference embedding\n",
        "    user_preference_embedding = user_preference_embedding / np.linalg.norm(user_preference_embedding)\n",
        "\n",
        "    # Calculate cosine similarity between user preference and product text embeddings\n",
        "    similarities = cosine_similarity([user_preference_embedding], text_embeddings).flatten()\n",
        "\n",
        "    # Weight similarities by the user's average rating\n",
        "    weighted_similarities = similarities * user_profile['avg_rating']\n",
        "\n",
        "    # Get top 5 recommended product IDs\n",
        "    top_5_indices = weighted_similarities.argsort()[-5:][::-1]\n",
        "    recommended_products = df.iloc[top_5_indices]['product_id'].tolist()\n",
        "\n",
        "    return recommended_products\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Test the Function (Updated)\n",
        "# Example: Get recommendations for user_id = 1\n",
        "user_id = 1\n",
        "recommended_products = recommend_products(user_id, user_history_df, df, combined_embeddings, text_embeddings)\n",
        "print(f\"\\nRecommended Products for User {user_id}: {recommended_products}\")\n",
        "\n",
        "# Example: Get recommendations for user_id = 2\n",
        "user_id = 2\n",
        "recommended_products = recommend_products(user_id, user_history_df, df, combined_embeddings, text_embeddings)\n",
        "print(f\"\\nRecommended Products for User {user_id}: {recommended_products}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUNXEIhAhtwV",
        "outputId": "ae6c2b8d-ff60-43a0-b85e-24287518f35f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recommended Products for User 1: [1, 2, 3]\n",
            "\n",
            "Recommended Products for User 2: [3, 1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2HRXU88of3Ml"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}